---
title: "Running the complete mapping process"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Running the complete mapping process}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  chunk_output_type: console
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(ROMOPMappingTools)
```

# Introduction

The `runAll` function provides a streamlined way to execute the complete mapping process:
1. Validates all Usagi files in a vocabulary folder
2. Creates and populates the SOURCE_TO_CONCEPT_MAP_EXTENDED table
3. Creates CDM vocabulary tables from the mappings
4. Validates the resulting CDM tables using DataQualityDashboard

# Required Setup

## File Structure

Your vocabulary folder should contain:
- A `vocabularies.csv` file describing the files (see the [File Format vignette](fileFormat.html))
- One subfolder for each vocabulary containing:
  - A Usagi mapping file (.csv)
  - A NEWS.md file with the release notes for the vocabulary

Example structure:
```
vocabularies/
├── vocabularies.csv
├── ICD10fi/
│   ├── NEWS.md
│   └── ICD10fi.usagi.csv
└── UNITfi/
    ├── NEWS.md
    └── UNITfi.usagi.csv
```

For testing, you can use the folder structure that comes in this package.
```{r}
pathToVocabularyFolder <- system.file("testdata/VOCABULARIES", package = "ROMOPMappingTools")
```

## Database Connection

You'll need connection details to a database where:
- You have permissions to create and modify tables
- The OMOP Vocabulary tables are already loaded

For testing, you can use the DuckDB database that is included in the package.
```{r}
pathToOMOPVocabularyDuckDBfile <- helper_createATemporaryCopyOfTheOMOPVocabularyDuckDB()

connectionDetails <- DatabaseConnector::createConnectionDetails(
    dbms = "duckdb",
    server = pathToOMOPVocabularyDuckDBfile
)
```

# Running the Process

The next code block demonstrates using the `runAll()` function with parameters we set up above. 
The `pathToVocabularyFolder` references our test data folder created earlier. 
The `vocabularyDatabaseSchema` "main" matches our DuckDB test database. 
We leave `sourceToConceptMapTable` as `NULL` with will create the SourceToConceptMap table with the name "source_to_concept_map_extended".
The `validationResultsFolder` is set to a temporary directory to store the validation and DQD results. 
These parameters match the connection and file structure we established in the setup section.


```{r eval=FALSE}
# Define paths and parameters
pathToVocabularyFolder <- pathToVocabularyFolder
vocabularyDatabaseSchema <- "main"
sourceToConceptMapTable <- NULL # if NULL, the SourceToConceptMap table will be created with the name "source_to_concept_map_extended"
validationResultsFolder <- file.path(tempdir(), "validationResults")
dir.create(validationResultsFolder, showWarnings = FALSE, recursive = TRUE)

# Run the complete process
validationLogTibble <- runAll(
    connectionDetails = connectionDetails,
    pathToVocabularyFolder = pathToVocabularyFolder,
    vocabularyDatabaseSchema = vocabularyDatabaseSchema,
    sourceToConceptMapTable = sourceToConceptMapTable,
    validationResultsFolder = validationResultsFolder
)
```

# Understanding the Results

The function returns a tibble containing a log of the different steps in the process.

```{r}
#knitr::kable(validationLogTibble)
```

If any there is any error in the column `type` the process may have not finished correctly.

In that case you can find more details in the `message` column and the files ourputed in the `validationResultsFolder`.

## Output Files

The process creates several output files:

1. Validation Log:
   - `validationLogTibble.csv` - Contains the validation log

2. Validated vocabularies.csv (if errors were found):
   - `vocabularies.csv` - Contains the validated vocabularies

3. Validated Usagi Files (if errors were found):
   - `vocabularies/` - Directory containing validated vocabulary files
     - Each vocabulary gets its own subdirectory with validated Usagi files
     - Only created if validation errors were found

4. Data Quality Dashboard Results:
   - `resultsDQD.json` - Contains the full DQD results in JSON format

example of the folder structure:

```
validationResultsFolder/
├── validationLogTibble.csv
├── vocabularies.csv (if errors were found)
├── vocabularies/
│   ├── ICD10fi/
│   │   └── ICD10fi.usagi.csv (if errors were found)
│   └── UNITfi/
│       └── UNITfi.usagi.csv (if errors were found)
├── resultsDQD.json
```

You can view the DQD results in an interactive dashboard:
```{r eval=FALSE}
resultsDQDjson <- file.path(validationResultsFolder, "resultsDQD.json")
DataQualityDashboard::viewDqDashboard(resultsDQDjson)
```

## Database Changes

The process also creates or modifies several tables in your database:

1. SOURCE_TO_CONCEPT_MAP_EXTENDED:
   - Contains all validated mappings from Usagi files
   - Includes extended information like source domains and parent concepts

2. CDM Vocabulary Tables:
   - CONCEPT - New source concepts from your mappings
   - CONCEPT_RELATIONSHIP - Mapping relationships between source and standard concepts
   - CONCEPT_CLASS - New concept classes from your source vocabularies
   - VOCABULARY - New vocabulary entries for your source vocabularies

These tables are created in the schema specified by vocabularyDatabaseSchema.

## Troubleshooting

If you encounter errors (type = "ERROR" in the validation log):

1. Check the validation messages in the log tibble
2. Examine the validated Usagi files in the validationResultsFolder
3. Review the DQD results for specific quality issues
4. Fix any identified issues in your source Usagi files
5. Run the process again

For detailed information about specific errors and how to fix them, refer to the [File Format vignette](fileFormat.html).



